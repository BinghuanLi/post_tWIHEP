These are scripts running on post tWIHEPFrameworks
How to use IHEP farm:
   export PATH=$PATH:/afs/ihep.ac.cn/soft/common/sysgroup/hep_job/bin/
   to submit job:
    hep_sub job.sh -o job.log -e job.error
    job.sh is the shell script to run, IHEP farm needs execute right of job.sh, chmode + 777 job.sh
    job.log save the log of the job
    job.error save the error of the job
   to check job status:
    hep_q -u username
   to kill all job:
    hep_rm -a  
   to kill job by id:
    hep_rm jobid


rootplJobs:

    scripts used to prepare rootplas

        Pre-process the output of tWIHEPFramework
        Current Working Directory is BaseDir, please copy rootplJobs/Datacard/*.py to BaseDir
        makeHEPSubmit.py is the script to create HEP jobs at IHEP
        change frameworkDir, inputBaseDir, outputBaseDir, executable of this script so the job will:
            . run frameworkDir/executable
            . inputBaseDir should be the output of tWIHEPFramework
        <python makeHEPSubmit.py>
        this command will create a script all.sh
        <bash all.sh> 
        after all jobs finished
        <python resubmitJobs.py> to check failed jobs
        if any job failed, run <bash allMissingFiles.sh>
        after this, run <python mergeCheck.py> to remove unnecessary files
        you need to change baseDir and frameworkDir in skimLegacyAll.py 
        finally, submit job script allSkim.sh, this will run script skimLegacyAll.py, the output will be your rootplas for all years.

datacard stuff:
    scripts used to prepare datacards

    Step 1:
        Create Template Variations
        Current Working Direcotry is BaseDir, please copy LegacyV2/mvaTool/*.py to BaseDir
        change frameworkDir, inputBaseDir, outputBaseDir
        <python makeVarHEPJob.py>
        this command will create a script all.sh, directory Output
        <bash all.sh>
        this will submit all the jobs to IHEP farm to create all the template needed for all the sub categories
        each job runs mvaTool.C 

    Step 2 :
        create datacard
        In datacard_Template.py createDatacardRootFile.py, you can tune the processes and nuisances
        <python runCreateTemplate.py> to create the template


    now you have everything needed for combine fitting

combJobs:
  
    You need to login to lxslc7.ihep.ac.cn for the combination 
    please set up combineTool and Harvester following instruction from:
        http://cms-analysis.github.io/HiggsAnalysis-CombinedLimit/#introduction 
        
    Here are the scripts used for submit combine fitting jobs
    goes into CMSSW/src/
    cmsenv
    create a directory "test"(for example)
    cd test/
    copy combJobs/LegacyV2/*.py .
    manipulate_datacards.py is used to combine all the datacards you produced before, you need to change the input path of this manipuldate_datacards.py
    python <make_newComJobs.py>
    this will create jobs for the fits
    <bash all.sh>
    this will submit all the combine fitting job to IHEP farm

    <plotLimit.py> is a tool to collect limit result, you can use it to optimize #bin
        
